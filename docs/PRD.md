PRD: Enterprise House Pricing Engine (M-HPE)
Version : 1.0.0 
Type : End-to-End MLOps Platform
Lead Architect : cSagombaye
Infrastructure : Local Cloud Simulation (Docker Compose / MinIO / Airflow)
Target SLA : < 200ms latency, 99.9% availability during retraining.

1. Executive Summary
Le projet M-HPE (Modular House Pricing Engine) vise √† simuler l'infrastructure de pricing d'une "Big Tech" immobili√®re (type Zillow/SeLoger).
Contrairement √† un projet de Data Science classique, la valeur ne r√©side pas dans la complexit√© math√©matique du mod√®le, mais dans la r√©silience du pipeline de livraison. Le syst√®me doit √™tre capable d'ing√©rer, nettoyer, entra√Æner, valider, d√©ployer et monitorer des mod√®les de r√©gression sans intervention humaine manuelle.

2. Project Components (Functional Requirements)
üß± Component 1: Data Pipeline & Preprocessing (The Foundation)
Ingestion : Scripts modulaires (src/data/ingestion.py) simulant l'arriv√©e de donn√©es brutes (batchs temporels).
Validation (Quality Gate 1) :
Utilisation de Pydantic et Pandas pour rejeter les donn√©es corrompues (ex: surface < 0, prix manquant).
Arr√™t imm√©diat du pipeline si la qualit√© des donn√©es est < 95%.
Versioning :
DVC (Data Version Control) tracke les fichiers .csv et .parquet.
Storage Backend : MinIO (simulation S3 local) ou dossier local partag√©.
Feature Engineering : Pipeline Scikit-learn sauvegard√© (Pickle) pour garantir que les transformations (Scaling, One-Hot) sont identiques en Training et en Serving.

üß† Component 2: Model Development (The Factory)
Design Pattern : Utilisation du Strategy Pattern pour l'interchangeabilit√© des algorithmes.
V1 : Scikit-learn (Linear Regression / Random Forest).
V2 : PyTorch (Pr√©paration de l'architecture pour le futur).
Experiment Tracking :
MLflow capture : Param√®tres, M√©triques (RMSE, MAE), Dataset Commit Hash (Git+DVC), et l'artefact du mod√®le.
Tuning : Impl√©mentation d'une GridSearch configurable via config/model.yaml (pas de hardcoding).
Registry : Le meilleur mod√®le est promu au statut "Staging" dans MLflow Model Registry.

‚öôÔ∏è Component 3: CI/CD Pipeline (The Guardrails)
Trigger : GitHub Actions se d√©clenche √† chaque push sur main ou develop.
Automated Tests (Quality Gate 2) :
Unit Tests : V√©rifient les fonctions de nettoyage.
Integration Tests : V√©rifient que le pipeline train -> predict ne crashe pas.
Continuous Deployment (CD) :
Si les tests passent : Build de l'image Docker app:latest.
Push (simul√©) vers un Registry.

üöÄ Component 4: Deployment & Serving (The Storefront)

Serving Engine : FastAPI (Asynchrone, haute performance).
Architecture :
Mod√®le charg√© en Singleton (1 seule instance en RAM).
Chargement dynamique : L'API tire le mod√®le tagu√© "Production" depuis MLflow au d√©marrage.
Security :
API Key Authentication (Header X-API-KEY).
Rate Limiting (ex: 100 req/min) pour √©viter le DDOS.
Container : Docker Multi-stage build (Image finale < 500Mo).

üëÅÔ∏è Component 5: Monitoring & Observability (The Control Tower)

System Metrics : Prometheus scrape /metrics (CPU, RAM, Latence, RPM, Error Rate).
Visualisation : Grafana avec Dashboards pr√©-configur√©s (Provisioning as Code).
Data Observability :
Evidently AI compare la distribution des requ√™tes live (Production) vs donn√©es d'entra√Ænement (Reference).
D√©tection de Data Drift (ex: les maisons deviennent plus grandes) et Concept Drift (le prix au m¬≤ change).

üîÑ Component 6: Feedback Loop & Retraining (The Automation)

Orchestrator : Apache Airflow (Dockeris√©).
Trigger Policy :
Schedule : Hebdomadaire (Cron).
Event-based : Si Evidently d√©tecte un Drift > 20%, appel API vers Airflow pour forcer un r√©-entra√Ænement (dvc repro).
Evaluation Automatique : Le nouveau mod√®le n'est d√©ploy√© que si son RMSE est meilleur que celui du mod√®le actuel (Champion/Challenger).

üîí Component 7: Security & Standards (The Compliance)

Secrets Management : AUCUN mot de passe dans le code. Utilisation stricte de .env inject√© par Docker Compose.
Least Privilege : Les conteneurs Docker tournent en tant qu'utilisateur non-root.
Logs : Audit trail de toutes les requ√™tes (ID, Timestamp, Input, Prediction) stock√© dans des logs rotatifs.

3. Configuration & File Standards

Pour garantir l'hygi√®ne du projet, les r√®gles suivantes sont strictes.
A. Gestion des Exclusions
.dockerignore (Optimisation Build)
code
Text
.git
.github
.venv
.env
__pycache__
data/            # Les donn√©es sont mont√©es en volume, pas copi√©es
notebooks/
tests/
docs/
airflow/         # L'API n'a pas besoin d'Airflow
monitoring/

.gitignore (Hygi√®ne Git)
code
Text
.venv/
.env
*.pkl
*.log
data/            # Sauf fichiers .dvc
dist/
.coverage
.pytest_cache/

B. Gestion des Environnements
.venv : Environnement virtuel local (cr√©√© par Poetry ou venv). Ne jamais toucher √† l'environnement syst√®me de Windows/WSL.
.env : Fichier unique contenant les secrets.
Exemple : MLFLOW_S3_ENDPOINT_URL=http://minio:9000

4. Roadmap d'Impl√©mentation (Sprint Plan)

Sprint 1 (Setup) : Git, Poetry, Structure de dossiers, Docker Compose "Core" (MinIO, Postgres).
Sprint 2 (Data & Model) : DVC Pipeline, code modulaire src/, Entra√Ænement Scikit-learn, MLflow Logging.
Sprint 3 (API & Docker) : FastAPI, Pydantic, Dockerfile optimis√©, Authentification.
Sprint 4 (Orchestration) : Airflow DAGs, Automatisation du dvc repro.
Sprint 5 (Monitoring) : Prometheus, Grafana, Evidently Drift Detection.

source .venv/bin/activate